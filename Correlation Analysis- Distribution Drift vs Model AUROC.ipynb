{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f804d8-a0f3-44a3-9300-2e34f2ca186e",
   "metadata": {},
   "source": [
    "# Correlation Analysis: Distribution Drift (KS/JS) vs Model AUROC\n",
    "\n",
    "This script computes correlations between **model distribution drift** (on scores & labels) and **model performance (AUROC)** for three tasks: **mortality, length-of-stay (LOS), and 30-day readmission**.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Inputs\n",
    "\n",
    "Located in the `results/` directory:\n",
    "\n",
    "- **Scored predictions** (row-level):  \n",
    "  - `mortality_scored_predictions.csv`  \n",
    "  - `los_scored_predictions.csv`  \n",
    "  - `readmit30_scored_predictions.csv`  \n",
    "  Each file must include:  \n",
    "  - `split_date` → which split this row belongs to  \n",
    "  - `admitdatetime` → timestamp (used to form weekly periods)  \n",
    "  - `y_true` → true binary label (0/1)  \n",
    "  - `y_pred` → predicted probability (0–1)\n",
    "\n",
    "- **Weekly drift CSVs** (already produced by the drift monitoring script):  \n",
    "  - `mortality_distribution_drift_weekly.csv`  \n",
    "  - `los_distribution_drift_weekly.csv`  \n",
    "  - `readmit30_distribution_drift_weekly.csv`  \n",
    "  Each file must include:  \n",
    "  - `split_date`, `week` (period start date)  \n",
    "  - `drift_score_KS` → Kolmogorov–Smirnov statistic on scores  \n",
    "  - `drift_label_JS` → Jensen–Shannon divergence on label distributions  \n",
    "  - (Optional: `drift_score_PSI` can also be used)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Processing Steps\n",
    "\n",
    "### a. Compute Weekly AUROC\n",
    "For each task:\n",
    "1. Add a `period` column (weekly bins of `admitdatetime`).\n",
    "2. For each `split_date` × `period`:\n",
    "   - Compute **AUROC** from `y_true` vs `y_pred`.\n",
    "   - Skip periods with only one class (AUROC undefined).\n",
    "\n",
    "**Output:** DataFrame with `split_date, week, n_week, auroc`.\n",
    "\n",
    "---\n",
    "\n",
    "### b. Align Drift with AUROC\n",
    "- Merge drift (`drift_score_KS`, `drift_label_JS`) with AUROC by `split_date` and `week`.\n",
    "\n",
    "---\n",
    "\n",
    "### c. Correlation Computation\n",
    "For each `metric ∈ {drift_score_KS, drift_label_JS}`:\n",
    "\n",
    "1. **Static correlations (lag=0):**  \n",
    "   - Pearson and Spearman correlations between drift and AUROC.\n",
    "\n",
    "2. **Lagged correlations (±6 weeks):**  \n",
    "   - Positive lag → **drift leads AUROC** (drift potentially predicts AUROC drop).  \n",
    "   - Negative lag → **AUROC leads drift**.\n",
    "\n",
    "**Metrics stored:**  \n",
    "- `split_date`, `metric`, `lag_weeks`, `pearson`, `spearman`, `n_pairs`.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Outputs\n",
    "\n",
    "- Per-task correlation tables:\n",
    "  - `mortality_ks_js_auroc_correlations.csv`  \n",
    "  - `los_ks_js_auroc_correlations.csv`  \n",
    "  - `readmit30_ks_js_auroc_correlations.csv`\n",
    "\n",
    "- Combined table across all tasks:\n",
    "  - `correlations_all_tasks.csv`\n",
    "\n",
    "Columns:\n",
    "- `task` → which task (mortality/los/readmit30)  \n",
    "- `split_date` → training split identifier  \n",
    "- `metric` → `\"SCORE_KS\"` or `\"LABEL_JS\"`  \n",
    "- `lag_weeks` → integer, positive means drift leads AUROC  \n",
    "- `pearson`, `spearman` → correlation coefficients  \n",
    "- `n_pairs` → number of aligned weeks used\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Interpretation\n",
    "\n",
    "- **High negative correlation (Pearson < 0) at lag=0:**  \n",
    "  Drift increases are associated with lower AUROC **at the same time**.\n",
    "\n",
    "- **High negative correlation at positive lag:**  \n",
    "  Drift changes **precede** AUROC degradation → early warning signal.\n",
    "\n",
    "- **Spearman vs Pearson:**  \n",
    "  - Pearson = linear relationship.  \n",
    "  - Spearman = monotonic (rank-based), robust to nonlinear patterns.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Example Workflow\n",
    "\n",
    "1. Run drift monitoring script → generates `{task}_distribution_drift_weekly.csv`.\n",
    "2. Run this correlation script → generates per-task + combined CSVs.\n",
    "3. Inspect:\n",
    "   - Static correlations → snapshot of drift ↔ performance alignment.  \n",
    "   - Lagged correlations → whether drift can **predict future AUROC shifts**.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Key Parameters\n",
    "\n",
    "| Parameter | Default | Meaning |\n",
    "|-----------|---------|---------|\n",
    "| `TASKS` | `[\"mortality\",\"los\",\"readmit30\"]` | Which tasks to process. |\n",
    "| `TIME_FREQ` | `\"W\"` | Period frequency (weekly). Must match drift CSV. |\n",
    "| `MAX_LAG` | `6` | Max lag (weeks) for correlation analysis. |\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Outputs for Visualization\n",
    "\n",
    "- CSV tables can be used to:\n",
    "  - Plot **correlation vs lag_weeks** curves.\n",
    "  - Compare across tasks (mortality vs LOS vs readmit30).\n",
    "  - Highlight **negative peaks at positive lags** (potential early warnings).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e821b933-02fe-44e6-8f69-bf6db1c4556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Correlation Analysis: Distribution Drift (KS/JS) vs AUROC\n",
    "# Loops over tasks: mortality, los, readmit30\n",
    "#\n",
    "# Inputs expected under ./results:\n",
    "#   - <task>_scored_predictions.csv           (columns: split_date, admitdatetime, y_true, y_pred)\n",
    "#   - <task>_distribution_drift_weekly.csv    (columns: split_date, week, drift_label_JS, drift_score_KS, ...)\n",
    "#\n",
    "# Outputs to ./results:\n",
    "#   - <task>_ks_js_auroc_correlations.csv\n",
    "#   - correlations_all_tasks.csv  (combined)\n",
    "# ============================================================\n",
    "\n",
    "import os, io, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.errors import EmptyDataError, ParserError\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# -------------------\n",
    "# Config\n",
    "# -------------------\n",
    "RESULTS_DIR = \"results\"\n",
    "TASKS = [\"mortality\", \"los\", \"readmit30\"]     # must match your file prefixes\n",
    "TIME_FREQ = \"W\"                               # should match how \"week\" was created in drift CSVs\n",
    "MAX_LAG = 6                                   # ± lag (in periods, e.g., weeks)\n",
    "SAVE_COMBINED = True\n",
    "\n",
    "# Columns in the drift CSV we’ll correlate with AUROC\n",
    "DRIFT_KS_COL = \"drift_score_KS\"\n",
    "DRIFT_JS_COL = \"drift_label_JS\"\n",
    "\n",
    "# -------------------\n",
    "# Safe I/O helpers\n",
    "# -------------------\n",
    "def safe_read_csv(path, parse_dates=None):\n",
    "    \"\"\"\n",
    "    Robust CSV reader: handles missing/empty/zero-byte files gracefully.\n",
    "    Returns (df, ok_bool). If ok_bool=False, df is empty.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"[WARN] File not found: {path}\")\n",
    "        return pd.DataFrame(), False\n",
    "    try:\n",
    "        if os.path.getsize(path) == 0:\n",
    "            print(f\"[WARN] Zero-byte file: {path}\")\n",
    "            return pd.DataFrame(), False\n",
    "    except OSError as e:\n",
    "        print(f\"[WARN] Could not stat file {path}: {e}\")\n",
    "        return pd.DataFrame(), False\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(path, parse_dates=parse_dates)\n",
    "    except EmptyDataError:\n",
    "        print(f\"[WARN] EmptyDataError: {path}\")\n",
    "        return pd.DataFrame(), False\n",
    "    except ParserError as e:\n",
    "        print(f\"[WARN] ParserError on {path}: {e}\")\n",
    "        return pd.DataFrame(), False\n",
    "    except UnicodeDecodeError:\n",
    "        # Try reading as binary then decode fallback\n",
    "        with open(path, \"rb\") as f:\n",
    "            raw = f.read()\n",
    "        try:\n",
    "            df = pd.read_csv(io.StringIO(raw.decode(\"utf-8\", errors=\"ignore\")), parse_dates=parse_dates)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Fallback read failed for {path}: {e}\")\n",
    "            return pd.DataFrame(), False\n",
    "    return df, True\n",
    "\n",
    "def atomic_write_csv(df, path):\n",
    "    \"\"\"Write CSV atomically to avoid zero-byte partial files.\"\"\"\n",
    "    tmp = path + \".tmp\"\n",
    "    df.to_csv(tmp, index=False)\n",
    "    os.replace(tmp, path)\n",
    "\n",
    "# -------------------\n",
    "# AUROC computation\n",
    "# -------------------\n",
    "def _add_period(df, date_col=\"admitdatetime\", freq=\"W\"):\n",
    "    out = df.copy()\n",
    "    out[date_col] = pd.to_datetime(out[date_col], errors=\"coerce\")\n",
    "    out[\"period\"] = out[date_col].dt.to_period(freq).dt.start_time\n",
    "    return out\n",
    "\n",
    "def compute_weekly_auroc(scored_df,\n",
    "                         date_col=\"admitdatetime\",\n",
    "                         split_col=\"split_date\",\n",
    "                         y_col=\"y_true\",\n",
    "                         p_col=\"y_pred\",\n",
    "                         freq=\"W\"):\n",
    "    \"\"\"\n",
    "    Returns DataFrame with columns: split_date, week, n_week, auroc\n",
    "    Skips periods that have only a single class (AUROC undefined).\n",
    "    \"\"\"\n",
    "    if scored_df.empty:\n",
    "        return pd.DataFrame(columns=[\"split_date\",\"week\",\"n_week\",\"auroc\"])\n",
    "\n",
    "    df = _add_period(scored_df, date_col=date_col, freq=freq)\n",
    "    req = {split_col, \"period\", y_col, p_col}\n",
    "    miss = req - set(df.columns)\n",
    "    if miss:\n",
    "        raise ValueError(f\"compute_weekly_auroc: missing columns {miss}\")\n",
    "\n",
    "    rows = []\n",
    "    for split, gsplit in df.groupby(split_col):\n",
    "        for per, g in gsplit.groupby(\"period\"):\n",
    "            y = g[y_col].dropna().astype(int).to_numpy()\n",
    "            p = g[p_col].dropna().astype(float).to_numpy()\n",
    "            # align after dropna\n",
    "            # ensure same length\n",
    "            n = min(len(y), len(p))\n",
    "            if n == 0:\n",
    "                continue\n",
    "            y, p = y[:n], p[:n]\n",
    "\n",
    "            if len(np.unique(y)) < 2:\n",
    "                # AUROC undefined for single-class period\n",
    "                continue\n",
    "            try:\n",
    "                auc = float(roc_auc_score(y, p))\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            rows.append({\n",
    "                \"split_date\": str(split),\n",
    "                \"week\": pd.to_datetime(per),\n",
    "                \"n_week\": int(len(y)),\n",
    "                \"auroc\": auc\n",
    "            })\n",
    "    out = pd.DataFrame(rows, columns=[\"split_date\",\"week\",\"n_week\",\"auroc\"])\n",
    "    return out.sort_values([\"split_date\",\"week\"]).reset_index(drop=True)\n",
    "\n",
    "# -------------------\n",
    "# Correlation logic\n",
    "# -------------------\n",
    "def _corr_pair(x, y):\n",
    "    \"\"\"Return (pearson, spearman, n) with NaNs handled; returns (None,None,0) if not enough pairs.\"\"\"\n",
    "    x = pd.Series(x).astype(float)\n",
    "    y = pd.Series(y).astype(float)\n",
    "    mask = x.notna() & y.notna()\n",
    "    x = x[mask]; y = y[mask]\n",
    "    n = int(len(x))\n",
    "    if n < 3:\n",
    "        return None, None, n\n",
    "    try:\n",
    "        pr = pearsonr(x, y)[0]\n",
    "    except Exception:\n",
    "        pr = None\n",
    "    try:\n",
    "        sr = spearmanr(x, y, nan_policy=\"omit\").correlation\n",
    "    except Exception:\n",
    "        sr = None\n",
    "    return (float(pr) if pr is not None and np.isfinite(pr) else None,\n",
    "            float(sr) if sr is not None and np.isfinite(sr) else None,\n",
    "            n)\n",
    "\n",
    "def correlate_drift_with_auroc(drift_df, auroc_df, metrics=(\"drift_score_KS\",\"drift_label_JS\"), max_lag=6):\n",
    "    \"\"\"\n",
    "    Per split_date: compute static (lag 0) and lagged (±max_lag) correlations between drift metrics and AUROC.\n",
    "    Returns a long DataFrame with columns: split_date, metric, lag_weeks, pearson, spearman, n_pairs\n",
    "    \"\"\"\n",
    "    if drift_df.empty or auroc_df.empty:\n",
    "        return pd.DataFrame(columns=[\"split_date\",\"metric\",\"lag_weeks\",\"pearson\",\"spearman\",\"n_pairs\"])\n",
    "\n",
    "    # Normalize types\n",
    "    drift = drift_df.copy()\n",
    "    drift[\"split_date\"] = drift[\"split_date\"].astype(str)\n",
    "    auroc = auroc_df.copy()\n",
    "    auroc[\"split_date\"] = auroc[\"split_date\"].astype(str)\n",
    "\n",
    "    rows = []\n",
    "    for split in sorted(set(drift[\"split_date\"]).intersection(set(auroc[\"split_date\"]))):\n",
    "        d = drift[drift[\"split_date\"] == split].copy()\n",
    "        a = auroc[auroc[\"split_date\"] == split].copy()\n",
    "\n",
    "        # Join on week (ensure datetime)\n",
    "        d[\"week\"] = pd.to_datetime(d[\"week\"], errors=\"coerce\")\n",
    "        a[\"week\"] = pd.to_datetime(a[\"week\"], errors=\"coerce\")\n",
    "\n",
    "        # Base merged frame at lag 0\n",
    "        base = pd.merge(d[[\"week\"] + list(metrics)], a[[\"week\",\"auroc\"]], on=\"week\", how=\"inner\").sort_values(\"week\")\n",
    "        if base.empty:\n",
    "            continue\n",
    "\n",
    "        # For each metric and lag\n",
    "        for metric in metrics:\n",
    "            # Static (lag 0)\n",
    "            pr, sr, n = _corr_pair(base[metric], base[\"auroc\"])\n",
    "            rows.append({\n",
    "                \"split_date\": split,\n",
    "                \"metric\": metric.replace(\"drift_\",\"\").upper(),\n",
    "                \"lag_weeks\": 0,\n",
    "                \"pearson\": pr, \"spearman\": sr, \"n_pairs\": n\n",
    "            })\n",
    "\n",
    "            # Lagged: positive lag => drift leads AUROC\n",
    "            for lag in range(1, max_lag + 1):\n",
    "                # Drift leads AUROC: AUROC shifted backward (future) relative to drift\n",
    "                lead = base.copy()\n",
    "                lead[\"auroc_shifted\"] = lead[\"auroc\"].shift(-lag)\n",
    "                pr, sr, n = _corr_pair(lead[metric], lead[\"auroc_shifted\"])\n",
    "                rows.append({\n",
    "                    \"split_date\": split, \"metric\": metric.replace(\"drift_\",\"\").upper(),\n",
    "                    \"lag_weeks\": +lag, \"pearson\": pr, \"spearman\": sr, \"n_pairs\": n\n",
    "                })\n",
    "\n",
    "                # AUROC leads drift: AUROC shifted forward (past) relative to drift\n",
    "                lagg = base.copy()\n",
    "                lagg[\"auroc_shifted\"] = lagg[\"auroc\"].shift(+lag)\n",
    "                pr, sr, n = _corr_pair(lagg[metric], lagg[\"auroc_shifted\"])\n",
    "                rows.append({\n",
    "                    \"split_date\": split, \"metric\": metric.replace(\"drift_\",\"\").upper(),\n",
    "                    \"lag_weeks\": -lag, \"pearson\": pr, \"spearman\": sr, \"n_pairs\": n\n",
    "                })\n",
    "\n",
    "    out = pd.DataFrame(rows, columns=[\"split_date\",\"metric\",\"lag_weeks\",\"pearson\",\"spearman\",\"n_pairs\"])\n",
    "    return out.sort_values([\"metric\",\"split_date\",\"lag_weeks\"]).reset_index(drop=True)\n",
    "\n",
    "# -------------------\n",
    "# Driver\n",
    "# -------------------\n",
    "def main():\n",
    "    os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "    combined = []\n",
    "\n",
    "    for task in TASKS:\n",
    "        print(f\"\\n==== {task.upper()} ====\")\n",
    "\n",
    "        # 1) Load drift CSV (produced by your moving-split drift script)\n",
    "        drift_path = os.path.join(RESULTS_DIR, f\"{task}_distribution_drift_weekly.csv\")\n",
    "        drift_df, ok = safe_read_csv(drift_path, parse_dates=[\"week\"])\n",
    "        if (not ok) or drift_df.empty:\n",
    "            print(f\"[WARN] Missing/empty drift CSV for '{task}': {drift_path}\")\n",
    "            continue\n",
    "\n",
    "        # Guard columns\n",
    "        need = {\"split_date\",\"week\", DRIFT_KS_COL, DRIFT_JS_COL}\n",
    "        missing = need - set(drift_df.columns)\n",
    "        if missing:\n",
    "            print(f\"[WARN] Drift CSV for '{task}' missing columns: {missing}. Skipping task.\")\n",
    "            continue\n",
    "\n",
    "        # 2) Load scored predictions and compute weekly AUROC\n",
    "        scored_path = os.path.join(RESULTS_DIR, f\"{task}_scored_predictions.csv\")\n",
    "        scored_df, ok = safe_read_csv(scored_path, parse_dates=[\"admitdatetime\"])\n",
    "        if (not ok) or scored_df.empty:\n",
    "            print(f\"[WARN] Missing/empty scored predictions for '{task}': {scored_path}\")\n",
    "            continue\n",
    "\n",
    "        # Guard columns\n",
    "        need_scored = {\"split_date\",\"admitdatetime\",\"y_true\",\"y_pred\"}\n",
    "        missing_scored = need_scored - set(scored_df.columns)\n",
    "        if missing_scored:\n",
    "            print(f\"[WARN] Scored predictions for '{task}' missing columns: {missing_scored}. Skipping task.\")\n",
    "            continue\n",
    "\n",
    "        auroc_df = compute_weekly_auroc(\n",
    "            scored_df,\n",
    "            date_col=\"admitdatetime\",\n",
    "            split_col=\"split_date\",\n",
    "            y_col=\"y_true\",\n",
    "            p_col=\"y_pred\",\n",
    "            freq=TIME_FREQ\n",
    "        )\n",
    "        if auroc_df.empty:\n",
    "            print(f\"[WARN] No weekly AUROC rows for '{task}' (single-class weeks or no overlap).\")\n",
    "            continue\n",
    "\n",
    "        # 3) Correlate (per split_date), static + lagged\n",
    "        corr_df = correlate_drift_with_auroc(\n",
    "            drift_df=drift_df,\n",
    "            auroc_df=auroc_df,\n",
    "            metrics=(DRIFT_KS_COL, DRIFT_JS_COL),\n",
    "            max_lag=MAX_LAG\n",
    "        )\n",
    "        if corr_df.empty:\n",
    "            print(f\"[WARN] No overlapping weeks between drift and AUROC for '{task}'.\")\n",
    "            continue\n",
    "\n",
    "        # 4) Save per-task CSV\n",
    "        out_task = os.path.join(RESULTS_DIR, f\"{task}_ks_js_auroc_correlations.csv\")\n",
    "        atomic_write_csv(corr_df, out_task)\n",
    "        print(f\"[OK] Saved correlations → {out_task} (rows={len(corr_df)})\")\n",
    "\n",
    "        # Quick console preview: static (lag=0)\n",
    "        static_preview = corr_df[corr_df[\"lag_weeks\"] == 0].copy()\n",
    "        if not static_preview.empty:\n",
    "            print(\"\\n-- Static correlations (lag=0) --\")\n",
    "            print(static_preview[[\"split_date\",\"metric\",\"pearson\",\"spearman\",\"n_pairs\"]].to_string(index=False))\n",
    "\n",
    "        corr_df = corr_df.copy()\n",
    "        corr_df.insert(0, \"task\", task)\n",
    "        combined.append(corr_df)\n",
    "\n",
    "    # 5) Save combined CSV across tasks\n",
    "    if SAVE_COMBINED and combined:\n",
    "        all_df = pd.concat(combined, ignore_index=True)\n",
    "        out_all = os.path.join(RESULTS_DIR, \"correlations_all_tasks.csv\")\n",
    "        atomic_write_csv(all_df, out_all)\n",
    "        print(f\"\\n[OK] Saved combined correlations → {out_all} (rows={len(all_df)})\")\n",
    "        # Optional: quick best-negative-corr preview at positive lags (drift leads)\n",
    "        try:\n",
    "            lead = all_df[all_df[\"lag_weeks\"] > 0].copy()\n",
    "            if not lead.empty:\n",
    "                best = (lead.sort_values([\"metric\",\"pearson\"], ascending=[True, True])\n",
    "                             .groupby([\"task\",\"metric\"]).head(3))\n",
    "                print(\"\\n-- Strongest (more negative) Pearson at positive lags (top 3 per task/metric) --\")\n",
    "                print(best[[\"task\",\"metric\",\"split_date\",\"lag_weeks\",\"pearson\",\"spearman\",\"n_pairs\"]].to_string(index=False))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    print(\"\\n[DONE] Correlation analysis complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24294b60-d37d-4145-b10d-daf207b7c9a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
